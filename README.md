# Knowledge-Driven-Visual-Association-Search-System

This project is an implementation of image and text feature extraction using CLIP and BLIP models. It also includes functionality for searching images by image and text features. 

## Features

- Extract image and text features using CLIP and BLIP models.
- Save features to a CSV file and a NumPy file.
- Search for images by image features.
- Search for images by generated text features from BLIP.

## Requirements

- Python 3.8+
- PyTorch
- transformers
- pandas
- numpy
- pillow
- matplotlib

## Installation

1. Clone the repository:

```bash
git clone <repository_url>
cd <repository_name>
```

2. Install the required packages:

```bash
pip install torch transformers pandas numpy pillow matplotlib
```

## Usage

### 1. Feature Extraction

Extract image and text features from the Flickr30k dataset and save them to a CSV file and a NumPy file.

### 2. Search

Search for images by image features or text features.

## Contributing

If you want to contribute to this project, please open an issue or create a pull request.

## License

This project is licensed under the MIT License.
